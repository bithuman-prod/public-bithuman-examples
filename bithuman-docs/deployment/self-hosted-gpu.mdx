---
title: "Self-Hosted GPU Container"
description: "Deploy GPU avatar workers on your infrastructure with full control over scaling, costs, and data privacy."
icon: "gpu-card"
---

<Info>
**Preview Feature** — 2 credits per minute while using the GPU container.
</Info>

## Overview

The self-hosted GPU avatar container (`docker.io/sgubithuman/expression-avatar:latest`) enables production-grade avatar generation on your own GPU infrastructure.

- **Full Control** — Complete control over deployment, scaling, and configuration
- **Cost Optimization** — Pay only for the GPU resources you use
- **Data Privacy** — Avatar images and audio never leave your infrastructure
- **Customization** — Extend the worker with custom logic and integrations

---

## Prerequisites

- NVIDIA GPU with **≥8 GB VRAM** (tested on H100, A100, RTX 4090)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) installed
- Docker 20.10+ or Docker Compose v2
- bitHuman API secret (`sk_bh_...`) from the [bitHuman Console](https://www.bithuman.ai)
- Model weights package from bitHuman (see below)

---

## Getting Model Weights

Model weights are provided by bitHuman as part of the Self-Hosted GPU access program.

<Info>
[Contact us](https://www.bithuman.ai) to request access and receive the model weights package.
</Info>

Once received, extract the weights so your directory looks like:

```
models/
├── bithuman-expression/    ← DiT model weights (~2 GB)
├── wav2vec2-base-960h/     ← audio encoder (~360 MB)
└── dit_lite_fp16.trt       ← TRT engine (~200 MB)
```

---

## Quick Start

```bash
# 1. Pull the image
docker pull docker.io/sgubithuman/expression-avatar:latest

# 2. Run with your model weights and API secret
docker run --gpus all -p 8089:8089 \
    -v /path/to/models:/data/models:ro \
    -e BITHUMAN_API_SECRET=sk_bh_... \
    docker.io/sgubithuman/expression-avatar:latest
```

```bash
# 3. Wait ~48s for startup, then check health
curl http://localhost:8089/health
# Returns: {"status": "healthy", "service": "expression-avatar", "active_sessions": 0, ...}
```

---

## Docker Compose Setup

Use the [full example](https://github.com/bithuman-product/examples/tree/main/public-docker-example) for a complete setup with LiveKit and a frontend:

```bash
git clone https://github.com/bithuman-product/examples.git
cd examples/public-docker-example

# Create .env.gpu with your credentials
echo "BITHUMAN_API_SECRET=sk_bh_..." > .env.gpu
echo "OPENAI_API_KEY=sk-..." >> .env.gpu

# Place model weights in ./models/
# (bithuman-expression/, wav2vec2-base-960h/, dit_lite_fp16.trt)

docker compose -f docker-compose.gpu.yml up
```

---

## Environment Variables

### BITHUMAN_API_SECRET (Required)

Your bitHuman API secret for billing. Each active avatar session is billed at **2 credits/minute**.

```bash
-e BITHUMAN_API_SECRET=sk_bh_...
```

<Warning>
Without `BITHUMAN_API_SECRET`, avatar sessions will run but usage will not be tracked or billed. This is not permitted for production use.
</Warning>

### Model Storage (Required)

Mount your model weights directory at `/data/models`:

```bash
-v /path/to/models:/data/models:ro
```

### How It Works

```
┌─────────────────────────────────────────────────────────────┐
│                    Avatar Generation Flow                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. Container Startup (~48s, one-time)                      │
│     └─ Load and compile models from /data/models            │
│                                                             │
│  2. Avatar Request                                          │
│     └─ avatar_image=<custom image>                          │
│        ├─ Encode image using local models (~2s)             │
│        └─ Generate frames at ~25 FPS                        │
│           → NO cloud calls (100% local GPU)                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## Performance Characteristics

| Configuration | Time to First Frame | Description |
|---------------|---------------------|-------------|
| Long-running + Preset | ~4 seconds | Avatar images pre-processed, minimal GPU init |
| Long-running + No Cache | ~6 seconds | Avatar processing on first request |
| Cold Start | ~48 seconds | Full avatar engine initialization + GPU compilation |

### Long-Running Containers (Recommended)

Containers stay running and handle multiple requests.

- Avatar engine initialized at startup (~48s one-time, includes GPU compilation)
- With presets: first frame in ~4s
- Without presets: first frame in ~6s
- Subsequent frames at ~25 FPS

### Cold Start Containers

Each request gets a fresh container.

- ~48s initialization time per container
- Higher latency per request, lower idle costs
- No persistent state between requests

---

## Troubleshooting

| Problem | Solution |
|---------|----------|
| Container won't start | Check GPU: `nvidia-smi`, verify model volume mount, check logs: `docker logs <id>` |
| Startup takes >2 min | GPU compilation runs once — subsequent starts use cached results |
| High first frame latency | Use long-running containers (avoid cold starts) |
| Out of memory | Use a GPU with ≥8 GB VRAM; the model requires ~5-6 GB VRAM |
| Billing not working | Verify `BITHUMAN_API_SECRET` is set correctly; check logs for `[HEARTBEAT]` messages |
| Models not found | Ensure volume mount path is correct and models directory contains all required files |

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Docker Example" icon="docker" href="https://github.com/bithuman-product/examples/tree/main/public-docker-example">
    Full GPU integration setup with LiveKit and frontend
  </Card>
  <Card title="LiveKit Agents" icon="book" href="https://docs.livekit.io/agents">
    LiveKit Agents documentation
  </Card>
</CardGroup>
