---
title: Welcome to BitHuman
description: Create lifelike digital avatars that respond to audio in real-time.
---

import { Cards, Card } from "fumadocs-ui/components/card";

Build interactive AI avatars for your applications with the BitHuman SDK and API.

<Cards>
  <Card title="Quick Start" description="Get up and running in 5 minutes" href="/docs/getting-started" />
  <Card title="API Reference" description="Complete REST API with interactive playground" href="/docs/api-reference" />
  <Card title="Cloud Services" description="Cloud plugin and self-hosted GPU deployment" href="/docs/cloud-services" />
  <Card title="Examples" description="Working examples from basic to advanced" href="/docs/examples" />
</Cards>

## Why BitHuman?

- **CPU-Only Operation** — Runs entirely on host CPU, no GPU required
- **10x Lower Costs** — Choose host device or CPU cloud for significant savings
- **Real-time Animation** — 25 FPS video with dynamic movement
- **Audio-driven** — Realistic facial movements from any audio input
- **Easy Integration** — 3 lines of code to get started
- **Web Ready** — Deploy to browsers with LiveKit integration

## Quick Example

```python
from bithuman import AsyncBithuman

runtime = await AsyncBithuman.create(
    model_path="model.imx",
    api_secret="your_secret"
)

async for frame in runtime.run():
    display(frame)
```
